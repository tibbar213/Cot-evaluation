# LLM评估项目需求规划

## 项目概述

本项目旨在评估大型语言模型（LLM）的基础能力和思维链（Chain of Thought, CoT）能力。通过实现多种CoT策略，对比分析不同策略对模型性能的影响，从而深入了解LLM的推理能力和优化方向。

## 技术栈

- **编程语言**：Python 3.9+
- **主要框架**：LangChain
- **模型接口**：OpenAI API
- **向量数据库**：FAISS/Chroma
- **评估工具**：自定义评估框架

## 模型配置

- **大模型**：通过OpenAI API调用（如GPT-4）
- **评估模型**：通过OpenAI API调用（如GPT-4）
- **向量模型**：BAAI/bge-m3（通过OpenAI API调用）

## 思维链（CoT）策略

本项目将实现并评估以下CoT策略：

### 1. Zero-shot CoT

在提示的最后添加"Let's think step by step."，引导模型进行逐步推理。

**示例**：
```
Q: 2+2等于多少？
A: Let's think step by step.
```

### 2. Few-shot CoT

使用向量数据库存储示例问题及其答案。对于每个测试问题：
1. 使用BAAI/bge-m3向量模型将问题转换为向量
2. 在向量数据库中搜索k个最相似的问题
3. 将这些相似问题及其答案作为示例，添加到提示中

**示例**：
```
Q: 小明有3个苹果，小红给了他2个，小明现在有几个苹果？
A: 小明原来有3个苹果，小红给了他2个，所以他现在有3+2=5个苹果。

Q: 小华有5本书，他借给了小丽1本，小华现在有几本书？
A: 小华原来有5本书，他借给了小丽1本，所以他现在有5-1=4本书。

Q: 小强有4个玩具，他弄丢了2个，小强现在有几个玩具？
A:
```

### 3. Auto-CoT

与Few-shot CoT类似，但为相似问题生成CoT推理过程：
1. 使用BAAI/bge-m3向量模型将问题转换为向量
2. 在向量数据库中搜索k个最相似的问题
3. 为这些相似问题生成CoT推理过程
4. 将这些相似问题及其生成的CoT推理过程作为示例，添加到提示中

**示例**：
```
Q: 小明有3个苹果，小红给了他2个，小明现在有几个苹果？
A: Let's think step by step。首先，我们需要知道小明原来有多少个苹果，是3个。然后，小红给了他2个，我们需要把这两个数加起来。3+2=5。所以小明现在有5个苹果。

Q: 小华有5本书，他借给了小丽1本，小华现在有几本书？
A: Let's think step by step。首先，我们需要知道小华原来有多少本书，是5本。然后，他借给了小丽1本，我们需要从5本书中减去1本。5-1=4。所以小华现在有4本书。

Q: 小强有4个玩具，他弄丢了2个，小强现在有几个玩具？
A:
```

### 4. AutoReason

对于每个测试问题，使用强模型生成详细的推理链，并将其作为提示的一部分：

**示例**：
```
Q: 小强有4个玩具，他弄丢了2个，小强现在有几个玩具？
A: (强模型提示词：您将获得一个问题，并使用该问题将其分解为一系列逻辑推理轨迹。仅写下推理过程，不要自己回答问题)
推理链：
1. 小强最初拥有的玩具数量
2. 小强丢失的玩具数量
3. 计算剩余玩具数量
最终答案：小强现在有2个玩具。
```

### 5. Auto-CoT + AutoReason

结合Auto-CoT和AutoReason的优势：
1. 使用BAAI/bge-m3向量模型将问题转换为向量
2. 在向量数据库中搜索k个最相似的问题
3. 使用DeepSeek-R1为这些相似问题生成CoT推理过程
4. 将这些相似问题及其生成的CoT推理过程作为示例，添加到提示中

**示例**：
```
Q: 迈克尔有58个高尔夫球。他在星期一的球场上丢了23个高尔夫球。星期二，他又在球场上丢了15个高尔夫球。他现在还有多少高尔夫球？  
A: (由DeepSeek-R1生成)
推理链：
1. 迈克尔一开始有58个高尔夫球。  
2. 他星期一丢了23个，所以58 - 23 = 35个高尔夫球剩下。  
3. 他星期二又丢了15个，所以35 - 15 = 20个高尔夫球剩下。  
4. 因此，迈克尔还剩20个高尔夫球。  

Q: 约翰有15美元。他买了两个苹果，每个苹果2美元。约翰还剩多少钱？  
A: (由DeepSeek-R1生成)
推理链：
1. 约翰一开始有15美元。  
2. 他买了两个每个2美元的苹果，总费用是2 * 2美元 = 4美元。  
3. 他剩下15美元 - 4美元 = 11美元。  
4. 因此，约翰还剩11美元。  

Q: 奥利维亚有23美元。她买了五个每个3美元的百吉饼。她还剩多少钱？  
A: 
```

### 6. Baseline（无CoT）

作为基准实验，直接向模型提问，不添加任何CoT提示。

## 评估指标

1. **准确率**：模型回答的正确率
2. **推理质量**：评估模型推理过程的合理性和逻辑性
3. **鲁棒性**：在不同类型问题上的表现一致性
4. **效率**：生成答案所需的时间和计算资源

## 项目结构

```
llm-evaluation/
├── docs/                  # 文档
│   └── requirements.md    # 需求文档
├── src/                   # 源代码
│   ├── config.py          # 配置文件
│   ├── models.py          # 模型接口
│   ├── vector_db.py       # 向量数据库接口
│   ├── strategies/        # CoT策略实现
│   │   ├── zero_shot.py   # Zero-shot CoT
│   │   ├── few_shot.py    # Few-shot CoT
│   │   ├── auto_cot.py    # Auto-CoT
│   │   ├── auto_reason.py # AutoReason
│   │   └── combined.py    # Auto-CoT + AutoReason
│   ├── evaluation.py      # 评估框架
│   └── main.py            # 主程序
├── data/                  # 测试数据
│   ├── questions.json     # 测试问题集
│   └── vector_store/      # 向量数据库存储
└── results/               # 评估结果
    └── eval_results.json  # 评估结果输出
```

## 实现计划

### 阶段一：环境搭建与基础功能

1. 安装必要的依赖库（LangChain、OpenAI、FAISS等）
2. 实现OpenAI API接口
3. 构建向量数据库框架

### 阶段二：CoT策略实现

1. 实现Zero-shot CoT策略
2. 实现Few-shot CoT策略
3. 实现Auto-CoT策略
4. 实现AutoReason策略
5. 实现Auto-CoT + AutoReason组合策略

### 阶段三：评估框架

1. 设计评估指标和方法
2. 实现评估模型接口
3. 开发评估结果分析工具

### 阶段四：测试与优化

1. 准备测试数据集
2. 对各策略进行评估
3. 分析比较不同策略的效果
4. 优化策略实现

## 依赖库

- langchain
- openai
- faiss-cpu (或 faiss-gpu)
- chromadb
- numpy
- pandas
- matplotlib (用于结果可视化)
- tqdm (进度显示)
- python-dotenv (环境变量管理)

## API密钥管理

项目将使用环境变量管理OpenAI API密钥，避免将敏感信息硬编码在代码中：

```python
# .env文件（不提交到版本控制）
OPENAI_API_KEY=your_api_key_here
```

## 注意事项

1. 需确保OpenAI API有足够的配额
2. 向量数据库可能需要较大存储空间
3. 评估过程可能耗费较多API调用，注意控制成本
4. 对于复杂问题，考虑设置较长的超时时间
